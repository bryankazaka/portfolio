<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Supervised Learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title">DEEPPC</a>
				<nav>
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="supervised_learning.html" class="active">Supervised Learning</a></li>
                        <li><a href="gans.html">Generative Adversarial Networks</a></li>
                        <li><a href="nas.html">Neural Architecture Search</a></li>			
					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major">Supervised Learning for Pathology Classifiers</h1>
							<h2>Overview</h2>
							<p>Deep learning uses powerful computers and large datasets to recognize patterns, especially in tasks related to images. One key method in deep learning is Supervised Learning. Here, the system learns from data with known labels and then uses this knowledge to identify new, unknown data.</p>
							<p>Medical datasets are small, which leads to overfitting, where a model learns the training data too closely and fails to generalise. One solution to overcome overfitting is through Data Augmentation (DA). DA makes small datasets more versatile by creating new data points that are consistent with the original ones. Another is through Transfer Learning (TL), which applies insights from one model to another. Additionally, several advanced network designs, like ConvNeXt, DenseNet, EffNet, and ResNet, have been developed to help in visual tasks. </p>
							<p>In the contemporary literature, many researchers are looking at ways to expand dataset sizes rather than finding the perfect system design for smaller datasets. This lead to our research questions:</p>
							<ol>
								<li>Which deep learning design is best for classifying multiple labels on small medical datasets?</li>
								<li>Can Data Augmentation improve the use of small medical datasets?</li>
								<li>Is "cross-domain Transfer Learning" useful when applying deep learning models to medical data?</li>
							</ol>

						</div>
					</section>
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major"></h1>
							<h2>Methods and Experiments</h2>
							<p>In our research, we looked into classifying multiple labels in computer vision using images of Neck and Elbow X-rays. We tested five design approaches: ConvNeXt, SwinTransformerv2, DenseNet, EfficientNetv2, and ResNet.</p>
							<p>For data improvement, we tried four techniques: not using any, Random Cropping, Rand Aug, and Neural Aug. Plus, we evaluated the performance with and without Transfer Learning for each dataset. In total, we reviewed 240 different model combinations.</p>
							<p>We used medical images given by Dr. Kruger from the Groote Schuur Hospital, processed them, and the models then predicted labels. We formulated a multi-label classification problem where a prediction was considered successful only if it matched exactly with the true label, due to the high importance of accuracy in medical imaging. This led to our detailed Experiments table below:</p>
							<table border="1">
								<thead>
									<tr>
										<th>Experiment</th>
										<th>Methods</th>
										<th>Variables</th>
										<th>Datasets</th>
										<th>Research Question</th>
									</tr>
								</thead>
								<tbody>
									<tr>
										<td>DL model architecture selection</td>
										<td>ConvNeXt, Swin-Tv2, DenseNet, EffNetv2, ResNet</td>
										<td>Parameter count, TL method, DA method</td>
										<td>Elbow and Neck</td>
										<td>Q1</td>
									</tr>
									<tr>
										<td>DA method selection</td>
										<td>Random Crop, Rand Aug, Neural Aug, No DA</td>
										<td>Model architecture, TL method</td>
										<td>Elbow and Neck</td>
										<td>Q2</td>
									</tr>
									<tr>
										<td>TL method selection</td>
										<td>ImageNet-1K pre-training, No TL</td>
										<td>Model architecture, No DA</td>
										<td>Elbow and Neck</td>
										<td>Q3</td>
									</tr>
								</tbody>
								<tfoot>
									<tr>
										<td colspan="2">Table 1: Experiment Design</td>
									</tr>
								</tfoot>
							</table>
							<p>We employ the following hyperparameters during training. Each of which was tuned manually:</p>
							<table border="1">
								<thead>
									<tr>
										<th>Hyperparameter</th>
										<th>Value</th>
									</tr>
								</thead>
								<tbody>
									<tr>
										<td>Activation Function</td>
										<td>Sigmoid, ReLU</td>
									</tr>
									<tr>
										<td>Cost Function</td>
										<td>Binary Cross Entropy</td>
									</tr>
									<tr>
										<td>Learning Rate</td>
										<td>1 × 10−3</td>
									</tr>
									<tr>
										<td>Weight Decay</td>
										<td>1 × 10−4 /10 steps</td>
									</tr>
									<tr>
										<td>Optimizer</td>
										<td>Adam</td>
									</tr>
									<tr>
										<td>Epochs</td>
										<td>15-TL, 30-No TL</td>
									</tr>
									<tr>
										<td>Batch Size</td>
										<td>32</td>
									</tr>
									<tr>
										<td>Image Size</td>
										<td>224x224</td>
									</tr>
									<tr>
										<td>Training Callbacks</td>
										<td>Early Stopping, Normalization</td>
									</tr>
								</tbody>
								<tfoot>
									<tr>
										<td colspan="2">Table 2: Hyperparameters values</td>
									</tr>
								</tfoot>
							</table>							
							<p>For Transfer Learning we use weights initialized on ImageNet-1K. For Data Augmentation, we use methods advised as proposed by their respective original paper implementations. See below for a demo of the effects of the different DA styles!</p>
							<section>
								<style>
									select {
										display: block;
										width: 200px;
										height: 30px;
										padding: 2px;
										font-size: 14px;
										color: black; 
										background-color: white;
										border: 1px solid #ccc;
										-webkit-appearance: none; 
										-moz-appearance: none; 
										appearance: none;
									}
									#middleContainer {
										display: flex;
										flex-direction: column;
										align-items: center;
										justify-content: center;
										width: 10%; 
										margin-left: 10%;
										margin-right: 10%;
									}
								</style>
								<div style="display: flex; justify-content: space-between; align-items: center;">
									<img src="images/NoDataAug.jpg" alt="Original Image" style="object-fit: contain; width: 224px; height: 224px;">
							
									<div id="middleContainer">
										<h3>&rarr;</h3>
										<select id="imageSelector">
											<option value="images/NoDataAug.jpg" selected>Original</option>
											<option value="images/RandomCrop.jpg">Random Cropping</option>
											<option value="images/RandAug.jpg">Rand Augment</option>
											<option value="images/NeuralAug.jpg">Neural Augment</option>
										</select>
									</div>
							
									<img id="rightImage" src="images/NoDataAug.jpg" alt="Modified Image" style="object-fit: contain; width: 224px; height: 224px;">
								</div>
							
								<script>
									document.getElementById("imageSelector").addEventListener("change", function() {
										var imageUrl = this.value;
										document.getElementById("rightImage").src = imageUrl;
									});
								</script>
							</section>
							
							
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major"></h1>
							<h2>Results and Conclusions</h2>
							<p>We conducted comprehensive research to find the best ways to analyze medical images. Among the many designs tested, the ConvNeXt stood out as the most effective. We also found that the Neural Augment technique was highly beneficial in improving our data usage, and Transfer Learning proved essential for accurate image classification.</p>
							<p>One challenge we faced was ensuring our data was balanced. Having a mix of various types of images was more critical than merely having lots of images. To address this, we introduced a method called "Default Validation." In simple terms, this method ensures images are labeled correctly based on what's detected in them.</p>

							<blockquote style="margin-left: 0;">
								<p>The prediction should indicate ’normal’ if no pathogens are identified in an image, and the ’normal’ label should be excluded if one or more pathogens are identified in an image.</p>
							</blockquote>
							
							<p>Here's a brief look at how Default Validation works:</p>
							<div style="font-family: 'Courier New', monospace; font-size:medium;">
								<p>Algorithm 1 Default Validation:</p>
								<p>1: for prediction in predictions do</p>
								<p>2: if all(prediction[:-1] == 0) then</p>
								<p>3: prediction[-1] ← 1</p>
								<p>4: else</p>
								<p>5: prediction[-1] ← 0</p>
								<p>6: end if</p>
								<p>7: end for</p>
							</div>
							
							
							
							<p>Thanks to this method, our models became more accurate by between 1.6% and 6.9%. The following are our top models in terms of Exact Match Ratio:</p>
							
							<h3>Elbow Images:</h3>
							<table border="1" style="width: 100%;">
								<thead>
									<tr>
										<th>Model</th>
										<th>Test Accuracy</th>
									</tr>
								</thead>
								<tbody>
									<tr>
										<td>ConvNeXt-B with TL and Neural Aug</td>
										<td>30.00</td>
									</tr>
									<tr>
										<td>(Baseline) ConvNeXt-B with No TL and No DA</td>
										<td>9.38</td>
									</tr>
								</tbody>
							</table>
							
							<h3>Neck Images:</h3>
							<table border="1" style="width: 100%;">
								<thead>
									<tr>
										<th>Model</th>
										<th>Test Accuracy</th>
									</tr>
								</thead>
								<tbody>
									<tr>
										<td>DenseNet121 with TL and Neural Aug</td>
										<td>48.44</td>
									</tr>
									<tr>
										<td>(Baseline) DensetNet121 with No TL and No DA</td>
										<td>39.06</td>
									</tr>
								</tbody>
							</table>
							
						</div>
					</section>
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major"></h1>
							<h2>Future Work</h2>
							<p>The study highlights areas where more research can be done. This includes looking into more methods for data augmentation and finding ways to address uneven data samples. Transfer learning has been helpful, but it might be even better if we learn from models focused on medical data. There's also potential to improve our current validation method by making a smarter system that can precisely analyze medical images.</p>
						</div>
					</section>
			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; University of Cape Town. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>